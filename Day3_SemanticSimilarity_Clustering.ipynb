{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ZAUkYk5SoLv"
   },
   "source": [
    "# Day 3: Semantic Similarity & Clustering\n",
    "\n",
    "- Use sentence embeddings (from Day 2) to compute semantic similarity.\n",
    "- Explore cosine similarity as a measure of closeness between sentence meanings.\n",
    "- Perform clustering using KMeans to group similar sentences.\n",
    "- Visualize clusters for interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"I love playing football.\",\n",
    "    \"Soccer is my favorite sport.\",\n",
    "    \"The weather is sunny today.\",\n",
    "    \"It's raining outside.\",\n",
    "    \"I enjoy watching movies on weekends.\",\n",
    "    \"Films are a great way to relax.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Mean pooling for sentence embeddings\n",
    "embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9A6FzqHQ97Bf"
   },
   "source": [
    "Before we move to cosine similarity, we need to ensure our sentence embeddings are accurate. Instead of taking a plain mean across all tokens (which includes padding), we’ll mask padding tokens using attention_mask.\n",
    "\n",
    "### Why Masked Mean Pooling?\n",
    "\n",
    "In BERT-based models:\n",
    "- `last_hidden_state` → gives embeddings for each token, including `[PAD]` tokens.\n",
    "- If we simply average all token embeddings, padding will skew results.\n",
    "\n",
    "To fix this:\n",
    "- Use `attention_mask` (1 for real tokens, 0 for padding).\n",
    "- Multiply embeddings by the mask.\n",
    "- Compute the mean only across actual tokens.\n",
    "\n",
    "This ensures better sentence-level representations for similarity tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output.last_hidden_state # [batch_size, seq_len, hidden_dim]\n",
    "    mask = attention_mask.unsqueeze(-1).expand(token_embeddings.size())\n",
    "    sum_embeddings = (token_embeddings * mask).sum(1)\n",
    "    sum_mask = mask.sum(1)\n",
    "    return sum_embeddings / sum_mask\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "sentence_embeddings = mean_pooling(outputs, inputs['attention_mask'])\n",
    "print(\"Shape of embeddings:\", sentence_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AvuEB4E0CDZn"
   },
   "source": [
    "Example explanation\n",
    "Suppose we have 3 tokens per sentence, each with 4-dimensional embeddings, and padding for unused positions.\n",
    "\n",
    "---\n",
    "\n",
    "Token embeddings (last_hidden_state):\n",
    "\n",
    "Sentence 1: [[1, 2, 3, 4], [2, 2, 2, 2], [0, 0, 0, 0]]  ← last row is padding\n",
    "\n",
    "Sentence 2: [[1, 1, 1, 1], [3, 3, 3, 3], [5, 5, 5, 5]]  ← all tokens are real\n",
    "\n",
    "---\n",
    "\n",
    "Attention mask:\n",
    "\n",
    "Sentence 1: [1, 1, 0]  → only first 2 tokens are real\n",
    "\n",
    "Sentence 2: [1, 1, 1]  → all tokens are real\n",
    "\n",
    "---\n",
    "Naive Mean (without masking)\n",
    "\n",
    "For Sentence 1:\n",
    "\n",
    "Sum all tokens → [1+2+0, 2+2+0, 3+2+0, 4+2+0] = [3, 4, 5, 6]\n",
    "\n",
    "Divide by 3 (total tokens) → [1, 1.33, 1.67, 2] ← padding skewed the mean downward.\n",
    "\n",
    "---\n",
    "\n",
    "Masked Mean Pooling\n",
    "\n",
    "Multiply embeddings by mask:\n",
    "\n",
    "Sentence 1: [[1,2,3,4], [2,2,2,2], [0,0,0,0]] × [1,1,0]\n",
    "→ [[1,2,3,4], [2,2,2,2], [0,0,0,0]]\n",
    "\n",
    "Sum → [3,4,5,6]\n",
    "\n",
    "Divide by sum of mask (1+1 = 2) → [1.5, 2, 2.5, 3] ← correct!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h2sjsd8XC2Xc"
   },
   "source": [
    "### PCA Visualization of Sentence Embeddings\n",
    "\n",
    "- Each sentence embedding from BERT is 768-dimensional (for `bert-base-uncased`).\n",
    "- Visualizing in 768 dimensions is impossible, so we use **PCA (Principal Component Analysis)**:\n",
    "  - PCA reduces dimensionality while preserving as much variance as possible.\n",
    "  - We project the embeddings from 768D → 2D.\n",
    "- This lets us visually inspect how sentences group based on meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Convert to numpy\n",
    "embeddings_np = sentence_embeddings.detach().numpy()\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=2)\n",
    "embeddings_2d = pca.fit_transform(embeddings_np)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], color='blue')\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    plt.annotate(f\"{i+1}\", (embeddings_2d[i, 0], embeddings_2d[i, 1]))\n",
    "\n",
    "plt.title(\"PCA of Sentence Embeddings\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35ZrgL2xDPvk"
   },
   "source": [
    "**Interpreting the PCA Plot**\n",
    "\n",
    "The PCA plot shows each sentence represented as a **point in 2D space**. Here’s how to read it:\n",
    "\n",
    "1. **Each point = one sentence embedding**  \n",
    "   - Numbers/labels correspond to the sentence index.\n",
    "\n",
    "2. **Distance = similarity (roughly)**  \n",
    "   - Points closer together mean their embeddings are more similar → sentences likely have similar meaning.\n",
    "   - Distant points → less semantic similarity.\n",
    "\n",
    "3. **Clusters = groups of semantically related sentences**  \n",
    "   - If multiple points form a cluster, the model sees them as related in meaning.\n",
    "   - For example, \"I love playing football\" and \"Soccer is my favorite sport\" should appear near each other.\n",
    "\n",
    "4. **Axes (PC1 & PC2)**  \n",
    "   - Do not directly represent any word or meaning.  \n",
    "   - They are **principal components**, directions that capture the most variance in high-dimensional data.\n",
    "\n",
    "5. **PCA is only an approximation**  \n",
    "   - We reduced from 768D → 2D, so some meaning relationships may get compressed or distorted.\n",
    "\n",
    "In short:\n",
    "- **Close points → semantically similar.**\n",
    "- **Far points → different topics.**\n",
    "- Clusters reveal **latent themes** within your text set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ORl3mTvlDp9h"
   },
   "source": [
    "### Cosine Similarity for Semantic Comparison\n",
    "\n",
    "Cosine similarity measures how close two vectors are in terms of their **direction**, not their length.\n",
    "\n",
    "- Formula:\n",
    "  **cos(θ) = (A · B) / (||A|| ||B||)**\n",
    "  \n",
    "- Values range from:\n",
    "  - **+1** → identical direction (high similarity)\n",
    "  - **0** → orthogonal (no similarity)\n",
    "  - **-1** → opposite direction (completely dissimilar)\n",
    "\n",
    "Why cosine similarity?\n",
    "- Sentence embeddings may differ in scale/magnitude.\n",
    "- Cosine similarity focuses on **meaningful orientation**, making it perfect for semantic comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Compute pairwise cosine similarity\n",
    "cos_sim_matrix = cosine_similarity(sentence_embeddings)\n",
    "\n",
    "print(\"Cosine Similarity Matrix:\\n\", np.round(cos_sim_matrix, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show pairwise similarities\n",
    "for i in range(len(sentences)):\n",
    "    for j in range(i + 1, len(sentences)):\n",
    "        print(f\"Similarity between '{sentences[i]}' and '{sentences[j]}': {cos_sim_matrix[i][j]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cos_sim_matrix, annot=True, cmap=\"coolwarm\", xticklabels=range(1, len(sentences)+1), yticklabels=range(1, len(sentences)+1))\n",
    "plt.title(\"Cosine Similarity Matrix (Sentence Embeddings)\")\n",
    "plt.xlabel(\"Sentence Index\")\n",
    "plt.ylabel(\"Sentence Index\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HuoN8zFFEeMG"
   },
   "source": [
    "**Why Cosine Similarity?**\n",
    "\n",
    "When working with sentence or word embeddings, each text is represented as a high-dimensional vector.\n",
    "- Two sentences with similar meaning may have embeddings with **different magnitudes** (lengths) but **similar directions**.\n",
    "- Example: \"I love football\" and \"I enjoy soccer\" may point in a similar direction in the embedding space but differ in vector length due to different words.\n",
    "\n",
    "**Cosine similarity solves this by focusing only on the angle between vectors:**\n",
    "- It measures **how close two vectors point to the same direction** regardless of their scale.\n",
    "\n",
    "---\n",
    "\n",
    "**How Does It Enable Semantic Similarity?**\n",
    "\n",
    "- In modern NLP models (like BERT, GPT), embeddings encode semantic meaning.\n",
    "- If two sentences mean the same thing, their embeddings tend to point in a **similar direction in the latent space**.\n",
    "- Cosine similarity helps us **quantify this semantic closeness**.\n",
    "\n",
    "**Example:**\n",
    "- \"The cat is on the mat\" vs \"A feline rests on the rug\" → High cosine similarity (meanings are close).\n",
    "- \"The cat is on the mat\" vs \"It’s raining today\" → Low cosine similarity (meanings are unrelated).\n",
    "\n",
    "This is why cosine similarity is widely used for:\n",
    "- **Semantic search**\n",
    "- **Clustering similar texts**\n",
    "- **Duplicate detection**\n",
    "- **Recommendation systems based on meaning rather than exact words**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9_zj_-pKFZLl"
   },
   "source": [
    "### Clustering Sentence Embeddings with KMeans\n",
    "\n",
    "- **What is KMeans?**\n",
    "  - A clustering algorithm that divides data points into *k* clusters.\n",
    "  - Each cluster is represented by a centroid (mean of points in that group).\n",
    "\n",
    "- **Why KMeans for text?**\n",
    "  - Our sentence embeddings are high-dimensional vectors.\n",
    "  - KMeans groups similar vectors together based on their positions in space.\n",
    "  - Useful for topic grouping, document clustering, or semantic organization.\n",
    "\n",
    "- **Key hyperparameter:**\n",
    "  - `n_clusters`: Number of groups we want. It should reflect how many distinct topics we expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Choose number of clusters (let's assume 3: sports, weather, movies)\n",
    "num_clusters = 3\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42, n_init=10)\n",
    "clusters = kmeans.fit_predict(sentence_embeddings)\n",
    "\n",
    "# Show cluster assignments\n",
    "for sentence, cluster_id in zip(sentences, clusters):\n",
    "    print(f\"[Cluster {cluster_id}] {sentence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DLfiZ6PAE94r"
   },
   "source": [
    "#### Choosing `n_clusters` for KMeans\n",
    "\n",
    "The number of clusters (`n_clusters`) is not always obvious, especially for text data.  \n",
    "Here are common strategies to determine it:\n",
    "\n",
    "---\n",
    "\n",
    "##### 1. **Domain Knowledge / Intuition**\n",
    "- If you already know how many topics or groups to expect, set `n_clusters` directly.\n",
    "- Example: If your dataset contains sentences about sports, weather, and movies, you might set `n_clusters=3`.\n",
    "\n",
    "---\n",
    "\n",
    "##### 2. **Elbow Method**\n",
    "- Plot the **inertia (within-cluster sum of squared distances)** for different cluster counts.\n",
    "- Inertia decreases as you add more clusters, but after a certain point, the improvement slows down → forming an \"elbow\" shape.\n",
    "- The elbow point suggests a good trade-off between too few and too many clusters.\n",
    "\n",
    "---\n",
    "\n",
    "##### 3. **Silhouette Score**\n",
    "- Measures how similar a point is to its own cluster compared to other clusters.\n",
    "- Ranges from **-1 (bad clustering) to +1 (good clustering)**.\n",
    "- Try multiple cluster counts and choose the one with the **highest silhouette score**.\n",
    "\n",
    "---\n",
    "\n",
    "##### 4. **Practical Simplicity**\n",
    "- For small datasets (like our 6-sentence example), using intuition is often enough.\n",
    "- For large datasets, combine the above methods for a more informed choice.\n",
    "\n",
    "---\n",
    "\n",
    "**In this project:**\n",
    "- We will start with **3 clusters** because our sentences intuitively belong to three topics:  \n",
    "  1. Sports (football, soccer)  \n",
    "  2. Weather (sunny, raining)  \n",
    "  3. Movies (films, weekends)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA again if not already available\n",
    "pca = PCA(n_components=2)\n",
    "embeddings_2d = pca.fit_transform(sentence_embeddings.detach().numpy())\n",
    "\n",
    "# Plot clusters\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(\n",
    "    embeddings_2d[:, 0], embeddings_2d[:, 1],\n",
    "    c=clusters, cmap='viridis', s=100\n",
    ")\n",
    "\n",
    "# Annotate points with sentence index\n",
    "for i, sentence in enumerate(sentences):\n",
    "    plt.annotate(f\"{i+1}\", (embeddings_2d[i, 0] + 0.02, embeddings_2d[i, 1]))\n",
    "\n",
    "plt.title(\"KMeans Clusters on Sentence Embeddings (PCA Reduced)\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.colorbar(scatter, label='Cluster ID')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rnjXsEYyGhWf"
   },
   "source": [
    "### Determining Optimal Number of Clusters\n",
    "\n",
    "- **Elbow Method**: Plots inertia (sum of squared distances within clusters) vs. number of clusters.\n",
    "  - Look for a \"bend\" or \"elbow\" in the curve.\n",
    "  - After this point, adding more clusters doesn't reduce inertia significantly.\n",
    "\n",
    "- **Silhouette Score**: Measures how well samples are clustered.\n",
    "  - Ranges from -1 (bad) to +1 (good).\n",
    "  - Higher = better defined clusters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "k_range = range(2, 6)  # testing from 2 to 5 clusters\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans_k = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = kmeans_k.fit_predict(sentence_embeddings)\n",
    "    inertias.append(kmeans_k.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(sentence_embeddings, labels))\n",
    "\n",
    "# Plot both metrics\n",
    "fig, ax1 = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "ax1.plot(list(k_range), inertias, 'b-o', label='Inertia (Elbow Method)')\n",
    "ax1.set_xlabel('Number of Clusters (k)')\n",
    "ax1.set_ylabel('Inertia', color='b')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(list(k_range), silhouette_scores, 'r-s', label='Silhouette Score')\n",
    "ax2.set_ylabel('Silhouette Score', color='r')\n",
    "\n",
    "plt.title(\"Elbow & Silhouette Analysis for KMeans\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9WWB7roSHX5y"
   },
   "source": [
    "- **Blue Line (Inertia)**:\n",
    "  - Inertia measures how tightly points are grouped within each cluster.\n",
    "  - Lower is better, but diminishing returns appear as clusters increase.\n",
    "  - In your plot, inertia keeps decreasing (as expected), but the \"bend\" is near **k = 3**.\n",
    "\n",
    "- **Red Line (Silhouette Score)**:\n",
    "  - Measures how distinct and well-separated clusters are.\n",
    "  - Higher is better (closer to +1 means well-defined clusters).\n",
    "  - Here, silhouette score is highest at **k = 2**, but drops after that.\n",
    "\n",
    "**Interpretation:**\n",
    "- If you care about *clear separation* → k = 2 is best.\n",
    "- If you care about *topic granularity (as per your dataset's 3 themes)* → k = 3 is a reasonable choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Ail72TNG1A8"
   },
   "source": [
    "### Alternative Visualization: Hierarchical Clustering or t-SNE\n",
    "\n",
    "- **Hierarchical Clustering**: Builds a tree of clusters (dendrogram).\n",
    "- **t-SNE**: Non-linear dimensionality reduction technique, better for visualizing high-dimensional embeddings.\n",
    "- **UMAP**: Similar to t-SNE but faster and preserves more global structure.\n",
    "\n",
    "Here we’ll try t-SNE to better visualize semantic relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Apply t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=5, n_iter=1000)\n",
    "tsne_embeddings = tsne.fit_transform(sentence_embeddings.detach().numpy())\n",
    "\n",
    "# Plot t-SNE clusters\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(tsne_embeddings[:, 0], tsne_embeddings[:, 1], c=clusters, cmap='viridis', s=100)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    plt.annotate(f\"{i+1}\", (tsne_embeddings[i, 0] + 0.02, tsne_embeddings[i, 1]))\n",
    "\n",
    "plt.title(\"t-SNE Visualization of Sentence Clusters\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UeZoFOp_Hlkf"
   },
   "source": [
    "- Each point is a sentence embedding reduced to 2D using t-SNE.\n",
    "- Colors represent KMeans cluster assignments.\n",
    "- Numbers are sentence indices.\n",
    "\n",
    "**Observations:**\n",
    "- Points with similar topics are closer together.\n",
    "- For example:\n",
    "  - Sentences 1 & 2 are grouped (likely similar topic).\n",
    "  - Sentence 5 is slightly isolated (possible outlier or unique context).\n",
    "- Clusters are reasonably separated but not perfectly — normal for small datasets.\n",
    "\n",
    "**Key Note:**\n",
    "- t-SNE emphasizes local relationships, not exact distances.\n",
    "- Distances between far-apart clusters are less meaningful than cluster tightness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lu1s7J9wG-Dd"
   },
   "source": [
    "### Semantic Search Demo\n",
    "\n",
    "We can now use our embeddings to build a **basic semantic search engine**:\n",
    "- Take a query sentence.\n",
    "- Compute its embedding.\n",
    "- Calculate cosine similarity with all sentence embeddings.\n",
    "- Return the most semantically similar sentence(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"I enjoy watching sports.\"\n",
    "query_inputs = tokenizer(query, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    query_output = model(**query_inputs)\n",
    "query_embedding = mean_pooling(query_output, query_inputs['attention_mask'])\n",
    "\n",
    "# Compute similarity with existing sentences\n",
    "similarities = cosine_similarity(query_embedding, sentence_embeddings).flatten()\n",
    "\n",
    "# Find top match\n",
    "top_idx = similarities.argmax()\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Most similar: {sentences[top_idx]} (score: {similarities[top_idx]:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HtNhLkAPHq3V"
   },
   "source": [
    "# **SUMMARY**\n",
    "\n",
    "## **What We Explored**\n",
    "- Learned how to measure **semantic similarity** between sentences using embeddings.\n",
    "- Used **cosine similarity** to quantify closeness between sentence vectors.\n",
    "- Performed **KMeans clustering** to group semantically similar sentences.\n",
    "- Visualized embeddings using **PCA and t-SNE** to observe natural clusters.\n",
    "- Applied **Elbow Method & Silhouette Analysis** to decide the optimal number of clusters.\n",
    "- Built a **mini semantic search engine** to retrieve the most relevant sentence to a query.\n",
    "\n",
    "---\n",
    "\n",
    "## **Key Concepts**\n",
    "1. **Cosine Similarity**\n",
    "   - Measures the angle between two vectors.\n",
    "   - Closer to **1 → more similar**, closer to **0 → less similar**.\n",
    "\n",
    "2. **Clustering**\n",
    "   - **KMeans** groups sentences into clusters by minimizing within-cluster variance.\n",
    "   - `n_clusters` determines how many groups to form.\n",
    "   - **Choosing k**:\n",
    "     - *Elbow Method* → find the bend where inertia reduction slows down.\n",
    "     - *Silhouette Score* → choose k with the highest cluster separation.\n",
    "\n",
    "3. **Dimensionality Reduction**\n",
    "   - **PCA**: Linear technique to project high-dimensional data into 2D for visualization.\n",
    "   - **t-SNE**: Non-linear technique, preserves local structure, better for small datasets.\n",
    "\n",
    "4. **Semantic Search**\n",
    "   - Compute embedding for query → Compare with dataset embeddings → Retrieve most similar.\n",
    "\n",
    "---\n",
    "\n",
    "## **Insights from Our Data**\n",
    "- Elbow & silhouette suggest **k=2 or k=3** as reasonable choices.\n",
    "- t-SNE visualization showed logical grouping but with slight overlap (expected for small datasets).\n",
    "- Semantic search worked by retrieving the most contextually similar sentence.\n",
    "\n",
    "---\n",
    "\n",
    "## **Key Functions & Parameters Used**\n",
    "- **Hugging Face Trans**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
